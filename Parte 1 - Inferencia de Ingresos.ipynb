{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autores Waren Sanchez | 2023-1198"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 1 DEL PROYECTO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A continuación se trabajaran los puntos de la sección \"Detalles de la Implementación\" del documento PDF sobre la Descripción del Proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0-) Importaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.1-) Importación de librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para manejo y manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Para visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para preprocesamiento de datos\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Para modelos de Machine Learning\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Para evaluación de modelos\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2-) Importación del dataset crudo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas:\n",
    "\n",
    "ruta_dekho = './Datasets_CSV/CAR_DETAILS_FROM_CAR_DEKHO.csv'\n",
    "ruta_prediction = './Datasets_CSV/car_price_prediction.csv'\n",
    "ruta_used = './Datasets_CSV/Used_Car_Dataset.csv'\n",
    "ruta_dvm = './Datasets_CSV/DVM-CAR_Dataset-Ad_table.csv'\n",
    "ruta_world = './Datasets_CSV/CarsDataWorld.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets:\n",
    "\n",
    "df_dekho = pd.read_csv(ruta_dekho)\n",
    "df_prediction = pd.read_csv(ruta_prediction)\n",
    "df_used = pd.read_csv(ruta_used)\n",
    "df_dvm = pd.read_csv(ruta_dvm, low_memory=False)\n",
    "df_world = pd.read_csv(ruta_world)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1-) Antes de todo el proceso de arreglar los datos y combinarlos en uno solo, primero debemos visualizar cada archivo, nos interesa ver cuales columnas coinciden en cuanto a la información que ofrecen y su tipo de dato. Asi sabremos a cuales deberías actualizar su tipo de dato, a cuales debemos fusionar en una sola basándonos en su coincidencia y a cuales deberíamos eliminar debido a que no logro coincidir entre los 5 datasets.\n",
    "\n",
    "Solo se tomaran en cuenta los datos que coincidan en cuanto a información entre los 5 datasets, los que no logren coincidir con los demás serán eliminados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Car Dekho: CAR_DETAILS_FROM_CAR_DEKHO.csv ---\n",
      "Columnas y tipos de datos:\n",
      "name             object\n",
      "year              int64\n",
      "selling_price     int64\n",
      "km_driven         int64\n",
      "fuel             object\n",
      "seller_type      object\n",
      "transmission     object\n",
      "owner            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "--- Car Price Prediction: car_price_prediction.csv ---\n",
      "Columnas y tipos de datos:\n",
      "ID                    int64\n",
      "Price                 int64\n",
      "Levy                 object\n",
      "Manufacturer         object\n",
      "Model                object\n",
      "Prod. year            int64\n",
      "Category             object\n",
      "Leather interior     object\n",
      "Fuel type            object\n",
      "Engine volume       float64\n",
      "Mileage              object\n",
      "Cylinders           float64\n",
      "Gear box type        object\n",
      "Drive wheels         object\n",
      "Doors                object\n",
      "Wheel                object\n",
      "Color                object\n",
      "Airbags               int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "--- DVM Car Dataset: DVM-CAR_Dataset-Ad_table.csv ---\n",
      "Columnas y tipos de datos:\n",
      "Maker           object\n",
      "Genmodel        object\n",
      "Genmodel_ID     object\n",
      "Adv_ID          object\n",
      "Adv_year         int64\n",
      "Adv_month        int64\n",
      "Color           object\n",
      "Reg_year         int64\n",
      "Bodytype        object\n",
      "Runned_Miles     int64\n",
      "Engin_size      object\n",
      "Gearbox         object\n",
      "Fuel_type       object\n",
      "Price            int64\n",
      "Seat_num         int64\n",
      "Door_num         int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "--- Used Car Auction Prices: Used_Car_Auction_Prices_car_prices.csv ---\n",
      "Error al leer el archivo Used_Car_Auction_Prices_car_prices.csv: [Errno 2] No such file or directory: './Datasets_CSV/Used_Car_Auction_Prices_car_prices.csv'\n",
      "\n",
      "--- Used Car Dataset: Used_Car_Dataset.csv ---\n",
      "Columnas y tipos de datos:\n",
      "Unnamed: 0              int64\n",
      "car_name               object\n",
      "registration_year      object\n",
      "insurance_validity     object\n",
      "fuel_type              object\n",
      "seats                   int64\n",
      "kms_driven              int64\n",
      "ownsership             object\n",
      "transmission           object\n",
      "manufacturing_year      int64\n",
      "mileage(kmpl)         float64\n",
      "engine(cc)              int64\n",
      "max_power(bhp)          int64\n",
      "torque(Nm)              int64\n",
      "price(in lakhs)       float64\n",
      "dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lista de nombres de archivos y etiquetas\n",
    "files = [\n",
    "    (\"CAR_DETAILS_FROM_CAR_DEKHO.csv\", \"Car Dekho\"),\n",
    "    (\"car_price_prediction.csv\", \"Car Price Prediction\"),\n",
    "    (\"DVM-CAR_Dataset-Ad_table.csv\", \"DVM Car Dataset\"),\n",
    "    (\"Used_Car_Auction_Prices_car_prices.csv\", \"Used Car Auction Prices\"),\n",
    "    (\"Used_Car_Dataset.csv\", \"Used Car Dataset\")\n",
    "]\n",
    "\n",
    "# Inspección de columnas y tipos de datos\n",
    "for file, label in files:\n",
    "    print(f\"--- {label}: {file} ---\")\n",
    "    try:\n",
    "        # Lee solo las primeras filas para inspección\n",
    "        df = pd.read_csv(f'./Datasets_CSV/{file}', nrows=10)\n",
    "        print(\"Columnas y tipos de datos:\")\n",
    "        print(df.dtypes)\n",
    "        print(\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo {file}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crearemos el nuevo csv que se encargara de recibir los datos de las demas columnas, es decir, sera el destino de fusion para los demas datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo CSV 'dataset_fusionado.csv' ha sido creado con las siguientes columnas y tipos de datos:\n",
      "Name             object\n",
      "Year              int64\n",
      "Price           float64\n",
      "Mileage         float64\n",
      "Fuel             object\n",
      "Transmission     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame con columnas específicas y tipos de datos predefinidos\n",
    "data = {\n",
    "    'Name': [],  # Cadenas de texto\n",
    "    'Year': [],  # Números enteros\n",
    "    'Price': [],  # Números con decimales\n",
    "    'Mileage': [],  # Números con decimales\n",
    "    'Fuel': [],  # Cadenas de texto\n",
    "    'Transmission': []  # Cadenas de texto\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_fusion = pd.DataFrame(data)\n",
    "\n",
    "# Cambiar los tipos de datos según sea necesario (aunque pandas lo hará automáticamente en muchos casos)\n",
    "df_fusion['Name'] = df_fusion['Name'].astype(str)\n",
    "df_fusion['Year'] = df_fusion['Year'].astype(int)\n",
    "df_fusion['Price'] = df_fusion['Price'].astype(float)\n",
    "df_fusion['Mileage'] = df_fusion['Mileage'].astype(float)\n",
    "df_fusion['Fuel'] = df_fusion['Fuel'].astype(str)\n",
    "df_fusion['Transmission'] = df_fusion['Transmission'].astype(str)\n",
    "\n",
    "# Guardar el DataFrame en un nuevo archivo CSV\n",
    "ruta_fusion = './Datasets_CSV/dataset_fusionado.csv'\n",
    "\n",
    "df_fusion.to_csv(ruta_fusion, index=False)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(f\"El archivo CSV 'dataset_fusionado.csv' ha sido creado con las siguientes columnas y tipos de datos:\")\n",
    "print(df_fusion.dtypes)\n",
    "\n",
    "df_fusion = pd.read_csv(ruta_fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abordar la eliminación de columnas que no son comunes en los cinco datasets, primero analizaremos las columnas presentes en cada uno y luego determinaremos cuáles son las que comparten información en común. Una vez identificadas, se mantendrán únicamente las columnas comunes, eliminando las restantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empezaremos el proceso de limpieza y organizacion adecuada de los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos un nuevo dataset a df_modificar\n",
    "df_Modificar = df_dekho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca eliminaremos las columnas de df_dekho que no son relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es df_dekho antes de eliminar las columnas no relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name             object\n",
      "year              int64\n",
      "selling_price     int64\n",
      "km_driven         int64\n",
      "fuel             object\n",
      "seller_type      object\n",
      "transmission     object\n",
      "owner            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_dekho.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminaremos las columnas innecesarias del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'df_dekho' CSV Data: \n",
      "\n",
      "name             object\n",
      "year              int64\n",
      "selling_price     int64\n",
      "km_driven         int64\n",
      "fuel             object\n",
      "seller_type      object\n",
      "transmission     object\n",
      "owner            object\n",
      "dtype: object\n",
      "\n",
      "CSV Data after deleting the columns:\n",
      "\n",
      "name             object\n",
      "year              int64\n",
      "selling_price     int64\n",
      "km_driven         int64\n",
      "fuel             object\n",
      "transmission     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display\n",
    "print(\"Original 'df_dekho' CSV Data: \\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Empezaremos a eliminar lo indeseado.\n",
    "columnasRelevantes = ['name', 'year', 'selling_price', 'km_driven', 'fuel', 'transmission']\n",
    "columnasParaEliminar = []\n",
    "\n",
    "# Identificamos y guardamos las columnas irrelevantes.\n",
    "for col in df_Modificar.columns:\n",
    "    if col not in columnasRelevantes:\n",
    "        columnasParaEliminar.append(col)\n",
    "\n",
    "# Eliminamos las columnas irrelevantes que fueron guardaas.\n",
    "df_Modificar = df_Modificar.drop(columnasParaEliminar, axis=1)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_dekho, index=False)\n",
    "\n",
    "# display\n",
    "print(\"\\nCSV Data after deleting the columns:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, ahora seguiremos con borrar las filas con datos nulos o NaN. Primero veamos cuantas filas tiene df_dekho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Original:\n",
      "                                     name  year  selling_price  km_driven  \\\n",
      "0                           Maruti 800 AC  2007          60000      70000   \n",
      "1                Maruti Wagon R LXI Minor  2007         135000      50000   \n",
      "2                    Hyundai Verna 1.6 SX  2012         600000     100000   \n",
      "3                  Datsun RediGO T Option  2017         250000      46000   \n",
      "4                   Honda Amaze VX i-DTEC  2014         450000     141000   \n",
      "...                                   ...   ...            ...        ...   \n",
      "4335  Hyundai i20 Magna 1.4 CRDi (Diesel)  2014         409999      80000   \n",
      "4336           Hyundai i20 Magna 1.4 CRDi  2014         409999      80000   \n",
      "4337                  Maruti 800 AC BSIII  2009         110000      83000   \n",
      "4338     Hyundai Creta 1.6 CRDi SX Option  2016         865000      90000   \n",
      "4339                     Renault KWID RXT  2016         225000      40000   \n",
      "\n",
      "        fuel transmission  \n",
      "0     Petrol       Manual  \n",
      "1     Petrol       Manual  \n",
      "2     Diesel       Manual  \n",
      "3     Petrol       Manual  \n",
      "4     Diesel       Manual  \n",
      "...      ...          ...  \n",
      "4335  Diesel       Manual  \n",
      "4336  Diesel       Manual  \n",
      "4337  Petrol       Manual  \n",
      "4338  Diesel       Manual  \n",
      "4339  Petrol       Manual  \n",
      "\n",
      "[4340 rows x 6 columns]\n",
      "\n",
      "DataFrame después de eliminar filas con valores NaN, vacíos y None:\n",
      "                                     name  year  selling_price  km_driven  \\\n",
      "0                           Maruti 800 AC  2007          60000      70000   \n",
      "1                Maruti Wagon R LXI Minor  2007         135000      50000   \n",
      "2                    Hyundai Verna 1.6 SX  2012         600000     100000   \n",
      "3                  Datsun RediGO T Option  2017         250000      46000   \n",
      "4                   Honda Amaze VX i-DTEC  2014         450000     141000   \n",
      "...                                   ...   ...            ...        ...   \n",
      "4335  Hyundai i20 Magna 1.4 CRDi (Diesel)  2014         409999      80000   \n",
      "4336           Hyundai i20 Magna 1.4 CRDi  2014         409999      80000   \n",
      "4337                  Maruti 800 AC BSIII  2009         110000      83000   \n",
      "4338     Hyundai Creta 1.6 CRDi SX Option  2016         865000      90000   \n",
      "4339                     Renault KWID RXT  2016         225000      40000   \n",
      "\n",
      "        fuel transmission  \n",
      "0     Petrol       Manual  \n",
      "1     Petrol       Manual  \n",
      "2     Diesel       Manual  \n",
      "3     Petrol       Manual  \n",
      "4     Diesel       Manual  \n",
      "...      ...          ...  \n",
      "4335  Diesel       Manual  \n",
      "4336  Diesel       Manual  \n",
      "4337  Petrol       Manual  \n",
      "4338  Diesel       Manual  \n",
      "4339  Petrol       Manual  \n",
      "\n",
      "[4340 rows x 6 columns]\n",
      "\n",
      "Cantidad de filas después de la limpieza: 4340\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame original\n",
    "print(\"DataFrame Original:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Paso 1: Reemplazar cadenas vacías y None por NaN\n",
    "df_Modificar.replace(['', None], pd.NA, inplace=True)\n",
    "\n",
    "# Paso 2: Eliminar filas con cualquier valor NaN\n",
    "df_Modificar = df_Modificar.dropna()\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_dekho, index=False)\n",
    "\n",
    "# Mostrar el DataFrame después de eliminar las filas con NaN, '', o None\n",
    "print(\"\\nDataFrame después de eliminar filas con valores NaN, vacíos y None:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Verificar la cantidad de filas después de la limpieza\n",
    "print(f\"\\nCantidad de filas después de la limpieza: {df_Modificar.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun parece, dekho no posee valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convirtamos los tipos de datos del dataset para que sean adecuados para la fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de df_dekho antes de la conversion:\n",
      "\n",
      "name             object\n",
      "year              int64\n",
      "selling_price     int64\n",
      "km_driven         int64\n",
      "fuel             object\n",
      "transmission     object\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos de df_dekho despues de la conversion:\n",
      "\n",
      "name              object\n",
      "year               int64\n",
      "selling_price    float64\n",
      "km_driven        float64\n",
      "fuel              object\n",
      "transmission      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipos de datos de df_dekho antes de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Cambiar los tipos de datos de las columnas\n",
    "df_Modificar['selling_price'] = df_Modificar['selling_price'].astype(float)\n",
    "df_Modificar['km_driven'] = df_Modificar['km_driven'].astype(float)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_dekho, index=False)\n",
    "\n",
    "print(\"\\nTipos de datos de df_dekho despues de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora funcionaremos sus datos al dataset_fusionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de columnas del CSV antes de la Fusion: 0\n",
      "Cantidad de filas del CSV después de la fusión: 4340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\warre\\AppData\\Local\\Temp\\ipykernel_8184\\3117655699.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fusion = pd.concat([df_fusion, df_Modificar_select], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de columnas del CSV antes de la Fusion: {df_fusion.shape[0]}\")\n",
    "\n",
    "# Seleccionar solo las columnas necesarias de df_Modificar\n",
    "df_Modificar_select = df_Modificar[['name', 'year', 'selling_price', 'km_driven', 'fuel', 'transmission']]\n",
    "\n",
    "# Renombrar las columnas para que coincidan con las de df_fusion si es necesario\n",
    "df_Modificar_select.columns = ['Name', 'Year', 'Price', 'Mileage', 'Fuel', 'Transmission']\n",
    "\n",
    "# Concatenar df_Modificar_select a df_fusion\n",
    "df_fusion = pd.concat([df_fusion, df_Modificar_select], ignore_index=True)\n",
    "\n",
    "# Guardamos los cambios en el archivo CSV\n",
    "df_fusion.to_csv(ruta_fusion, index=False)\n",
    "\n",
    "# Verificar el resultado de la fusión\n",
    "print(f\"Cantidad de filas del CSV después de la fusión: {df_fusion.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora continuamos con df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos un nuevo dataset para df_Modificar.\n",
    "df_Modificar = df_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora eliminaremos las columnas que no sean relevantes de df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'df_dekho' CSV Data: \n",
      "\n",
      "ID                    int64\n",
      "Price                 int64\n",
      "Levy                 object\n",
      "Manufacturer         object\n",
      "Model                object\n",
      "Prod. year            int64\n",
      "Category             object\n",
      "Leather interior     object\n",
      "Fuel type            object\n",
      "Engine volume        object\n",
      "Mileage              object\n",
      "Cylinders           float64\n",
      "Gear box type        object\n",
      "Drive wheels         object\n",
      "Doors                object\n",
      "Wheel                object\n",
      "Color                object\n",
      "Airbags               int64\n",
      "car_name             object\n",
      "dtype: object\n",
      "\n",
      "CSV Data after deleting the columns:\n",
      "\n",
      "Price             int64\n",
      "Prod. year        int64\n",
      "Fuel type        object\n",
      "Mileage          object\n",
      "Gear box type    object\n",
      "car_name         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concatenaremos las columnas Model y Manufacturer.\n",
    "df_Modificar['car_name'] = df_Modificar['Manufacturer'] + ' ' + df_Modificar['Model']\n",
    "\n",
    "# display\n",
    "print(\"Original 'df_dekho' CSV Data: \\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Empezaremos a eliminar lo indeseado.\n",
    "columnasRelevantes = ['car_name', 'Prod. year', 'Price', 'Mileage', 'Fuel type', 'Gear box type']\n",
    "columnasParaEliminar = []\n",
    "\n",
    "# Identificamos y guardamos las columnas irrelevantes.\n",
    "for col in df_Modificar.columns:\n",
    "    if col not in columnasRelevantes:\n",
    "        columnasParaEliminar.append(col)\n",
    "\n",
    "# Eliminamos las columnas irrelevantes que fueron guardaas.\n",
    "df_Modificar = df_Modificar.drop(columnasParaEliminar, axis=1)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_prediction, index=False)\n",
    "\n",
    "# display\n",
    "print(\"\\nCSV Data after deleting the columns:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a eliminar cualquier valor nulo que tenga el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Original:\n",
      "       Price  Prod. year Fuel type    Mileage Gear box type  \\\n",
      "0      13328        2010    Hybrid  186005 km     Automatic   \n",
      "1      16621        2011    Petrol  192000 km     Tiptronic   \n",
      "2       8467        2006    Petrol  200000 km      Variator   \n",
      "3       3607        2011    Hybrid  168966 km     Automatic   \n",
      "4      11726        2014    Petrol   91901 km     Automatic   \n",
      "...      ...         ...       ...        ...           ...   \n",
      "19232   8467        1999       CNG  300000 km        Manual   \n",
      "19233  15681        2011    Petrol  161600 km     Tiptronic   \n",
      "19234  26108        2010    Diesel  116365 km     Automatic   \n",
      "19235   5331        2007    Diesel   51258 km     Automatic   \n",
      "19236    470        2012    Hybrid  186923 km     Automatic   \n",
      "\n",
      "                    car_name  \n",
      "0               LEXUS RX 450  \n",
      "1          CHEVROLET Equinox  \n",
      "2                  HONDA FIT  \n",
      "3                FORD Escape  \n",
      "4                  HONDA FIT  \n",
      "...                      ...  \n",
      "19232  MERCEDES-BENZ CLK 200  \n",
      "19233         HYUNDAI Sonata  \n",
      "19234         HYUNDAI Tucson  \n",
      "19235      CHEVROLET Captiva  \n",
      "19236         HYUNDAI Sonata  \n",
      "\n",
      "[19237 rows x 6 columns]\n",
      "\n",
      "DataFrame después de eliminar filas con valores NaN, vacíos y None:\n",
      "       Price  Prod. year Fuel type    Mileage Gear box type  \\\n",
      "0      13328        2010    Hybrid  186005 km     Automatic   \n",
      "1      16621        2011    Petrol  192000 km     Tiptronic   \n",
      "2       8467        2006    Petrol  200000 km      Variator   \n",
      "3       3607        2011    Hybrid  168966 km     Automatic   \n",
      "4      11726        2014    Petrol   91901 km     Automatic   \n",
      "...      ...         ...       ...        ...           ...   \n",
      "19232   8467        1999       CNG  300000 km        Manual   \n",
      "19233  15681        2011    Petrol  161600 km     Tiptronic   \n",
      "19234  26108        2010    Diesel  116365 km     Automatic   \n",
      "19235   5331        2007    Diesel   51258 km     Automatic   \n",
      "19236    470        2012    Hybrid  186923 km     Automatic   \n",
      "\n",
      "                    car_name  \n",
      "0               LEXUS RX 450  \n",
      "1          CHEVROLET Equinox  \n",
      "2                  HONDA FIT  \n",
      "3                FORD Escape  \n",
      "4                  HONDA FIT  \n",
      "...                      ...  \n",
      "19232  MERCEDES-BENZ CLK 200  \n",
      "19233         HYUNDAI Sonata  \n",
      "19234         HYUNDAI Tucson  \n",
      "19235      CHEVROLET Captiva  \n",
      "19236         HYUNDAI Sonata  \n",
      "\n",
      "[19237 rows x 6 columns]\n",
      "\n",
      "Cantidad de filas después de la limpieza: 19237\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame original\n",
    "print(\"DataFrame Original:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Paso 1: Reemplazar cadenas vacías y None por NaN\n",
    "df_Modificar.replace(['', None], pd.NA, inplace=True)\n",
    "\n",
    "# Paso 2: Eliminar filas con cualquier valor NaN\n",
    "df_Modificar = df_Modificar.dropna()\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_prediction, index=False)\n",
    "\n",
    "# Mostrar el DataFrame después de eliminar las filas con NaN, '', o None\n",
    "print(\"\\nDataFrame después de eliminar filas con valores NaN, vacíos y None:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Verificar la cantidad de filas después de la limpieza\n",
    "print(f\"\\nCantidad de filas después de la limpieza: {df_Modificar.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal parece que este tampoco tiene valores nulos, lo cual es perfecto, asi no perdemos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminemos km de Mileage, ya que nos impedira convertirlo a float durante la conversion, vamos a corregir eso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mileage antes de quitarle km:\n",
      "\n",
      "0        186005 km\n",
      "1        192000 km\n",
      "2        200000 km\n",
      "3        168966 km\n",
      "4         91901 km\n",
      "           ...    \n",
      "19232    300000 km\n",
      "19233    161600 km\n",
      "19234    116365 km\n",
      "19235     51258 km\n",
      "19236    186923 km\n",
      "Name: Mileage, Length: 19237, dtype: object\n",
      "Mileage despues de quitarle km:\n",
      "\n",
      "0        186005\n",
      "1        192000\n",
      "2        200000\n",
      "3        168966\n",
      "4         91901\n",
      "          ...  \n",
      "19232    300000\n",
      "19233    161600\n",
      "19234    116365\n",
      "19235     51258\n",
      "19236    186923\n",
      "Name: Mileage, Length: 19237, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Mileage antes de quitarle km:\n",
    "print(\"Mileage antes de quitarle km:\\n\")\n",
    "print(df_Modificar['Mileage'])\n",
    "\n",
    "# Limpiar la columna de Mileage de km\n",
    "df_Modificar['Mileage'] = df_Modificar['Mileage'].replace({' km': '', ',': ''}, regex=True)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_prediction, index=False)\n",
    "\n",
    "# Mileage despues de quitarle km:\n",
    "print(\"Mileage despues de quitarle km:\\n\")\n",
    "print(df_Modificar['Mileage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convirtamos los tipos de datos del dataset para que sean adecuados para la fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de CSV antes de la conversion:\n",
      "\n",
      "Price             int64\n",
      "Prod. year        int64\n",
      "Fuel type        object\n",
      "Mileage          object\n",
      "Gear box type    object\n",
      "car_name         object\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos del CSV despues de la conversion:\n",
      "\n",
      "Price            float64\n",
      "Prod. year         int64\n",
      "Fuel type         object\n",
      "Mileage          float64\n",
      "Gear box type     object\n",
      "car_name          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipos de datos de CSV antes de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Cambiar los tipos de datos de las columnas\n",
    "df_Modificar['Price'] = df_Modificar['Price'].astype(float)\n",
    "df_Modificar['Mileage'] = df_Modificar['Mileage'].astype(float)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_prediction, index=False)\n",
    "\n",
    "print(\"\\nTipos de datos del CSV despues de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora funcionaremos sus datos al dataset_fusionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de columnas del CSV antes de la Fusion: 4340\n",
      "Cantidad de filas del CSV después de la fusión: 23577\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de columnas del CSV antes de la Fusion: {df_fusion.shape[0]}\")\n",
    "\n",
    "# Seleccionar solo las columnas necesarias de df_Modificar\n",
    "df_Modificar_select = df_Modificar[['car_name', 'Prod. year', 'Price', 'Mileage', 'Fuel type', 'Gear box type']]\n",
    "\n",
    "# Renombrar las columnas para que coincidan con las de df_fusion si es necesario\n",
    "df_Modificar_select.columns = ['Name', 'Year', 'Price', 'Mileage', 'Fuel', 'Transmission']\n",
    "\n",
    "# Concatenar df_Modificar_select a df_fusion\n",
    "df_fusion = pd.concat([df_fusion, df_Modificar_select], ignore_index=True)\n",
    "\n",
    "# Guardamos los cambios en el archivo CSV\n",
    "df_fusion.to_csv(ruta_fusion, index=False)\n",
    "\n",
    "# Verificar el resultado de la fusión\n",
    "print(f\"Cantidad de filas del CSV después de la fusión: {df_fusion.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora continuamos con df_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos un nuevo dataset para df_Modificar.\n",
    "df_Modificar = df_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora eliminaremos las columnas que no sean relevantes de df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CSV Data: \n",
      "\n",
      "Unnamed: 0              int64\n",
      "car_name               object\n",
      "registration_year      object\n",
      "insurance_validity     object\n",
      "fuel_type              object\n",
      "seats                   int64\n",
      "kms_driven              int64\n",
      "ownsership             object\n",
      "transmission           object\n",
      "manufacturing_year     object\n",
      "mileage(kmpl)         float64\n",
      "engine(cc)            float64\n",
      "max_power(bhp)        float64\n",
      "torque(Nm)            float64\n",
      "price(in lakhs)       float64\n",
      "dtype: object\n",
      "\n",
      "CSV Data after deleting the columns:\n",
      "\n",
      "car_name               object\n",
      "fuel_type              object\n",
      "kms_driven              int64\n",
      "transmission           object\n",
      "manufacturing_year     object\n",
      "price(in lakhs)       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display\n",
    "print(\"Original CSV Data: \\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Empezaremos a eliminar lo indeseado.\n",
    "columnasRelevantes = ['car_name', 'manufacturing_year', 'price(in lakhs)', 'kms_driven', 'fuel_type', 'transmission']\n",
    "columnasParaEliminar = []\n",
    "\n",
    "# Identificamos y guardamos las columnas irrelevantes.\n",
    "for col in df_Modificar.columns:\n",
    "    if col not in columnasRelevantes:\n",
    "        columnasParaEliminar.append(col)\n",
    "\n",
    "# Eliminamos las columnas irrelevantes que fueron guardaas.\n",
    "df_Modificar = df_Modificar.drop(columnasParaEliminar, axis=1)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_used, index=False)\n",
    "\n",
    "# display\n",
    "print(\"\\nCSV Data after deleting the columns:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a eliminar cualquier valor nulo que tenga el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Original:\n",
      "                                               car_name fuel_type  kms_driven  \\\n",
      "0                       2017 Mercedes-Benz S-Class S400    Petrol       56000   \n",
      "1     2020 Nissan Magnite Turbo CVT XV Premium Opt BSVI    Petrol       30615   \n",
      "2                          2018 BMW X1 sDrive 20d xLine    Diesel       24000   \n",
      "3                              2019 Kia Seltos GTX Plus    Petrol       18378   \n",
      "4                       2019 Skoda Superb LK 1.8 TSI AT    Petrol       44900   \n",
      "...                                                 ...       ...         ...   \n",
      "1548           2020 Hyundai Creta SX Opt Diesel AT BSVI    Diesel       35000   \n",
      "1549                 2022 Renault KWID 1.0 RXL Opt BSVI    Petrol       10000   \n",
      "1550                           2017 Honda WR-V i-VTEC S    Petrol       49000   \n",
      "1551           2018 Volkswagen Polo 1.0 MPI Comfortline    Petrol       40000   \n",
      "1552                        2018 Maruti Swift Dzire VXI    Petrol       34756   \n",
      "\n",
      "     transmission manufacturing_year  price(in lakhs)  \n",
      "0       Automatic               2017            63.75  \n",
      "1       Automatic               2020             8.99  \n",
      "2       Automatic               2018            23.75  \n",
      "3          Manual               2019            13.56  \n",
      "4       Automatic               2019            24.00  \n",
      "...           ...                ...              ...  \n",
      "1548    Automatic               2020            17.41  \n",
      "1549         2022     Power Steering             3.98  \n",
      "1550       Manual               2017             5.85  \n",
      "1551       Manual               2018             4.75  \n",
      "1552       Manual               2018             6.10  \n",
      "\n",
      "[1553 rows x 6 columns]\n",
      "\n",
      "DataFrame después de eliminar filas con valores NaN, vacíos y None:\n",
      "                                               car_name fuel_type  kms_driven  \\\n",
      "0                       2017 Mercedes-Benz S-Class S400    Petrol       56000   \n",
      "1     2020 Nissan Magnite Turbo CVT XV Premium Opt BSVI    Petrol       30615   \n",
      "2                          2018 BMW X1 sDrive 20d xLine    Diesel       24000   \n",
      "3                              2019 Kia Seltos GTX Plus    Petrol       18378   \n",
      "4                       2019 Skoda Superb LK 1.8 TSI AT    Petrol       44900   \n",
      "...                                                 ...       ...         ...   \n",
      "1548           2020 Hyundai Creta SX Opt Diesel AT BSVI    Diesel       35000   \n",
      "1549                 2022 Renault KWID 1.0 RXL Opt BSVI    Petrol       10000   \n",
      "1550                           2017 Honda WR-V i-VTEC S    Petrol       49000   \n",
      "1551           2018 Volkswagen Polo 1.0 MPI Comfortline    Petrol       40000   \n",
      "1552                        2018 Maruti Swift Dzire VXI    Petrol       34756   \n",
      "\n",
      "     transmission manufacturing_year  price(in lakhs)  \n",
      "0       Automatic               2017            63.75  \n",
      "1       Automatic               2020             8.99  \n",
      "2       Automatic               2018            23.75  \n",
      "3          Manual               2019            13.56  \n",
      "4       Automatic               2019            24.00  \n",
      "...           ...                ...              ...  \n",
      "1548    Automatic               2020            17.41  \n",
      "1549         2022     Power Steering             3.98  \n",
      "1550       Manual               2017             5.85  \n",
      "1551       Manual               2018             4.75  \n",
      "1552       Manual               2018             6.10  \n",
      "\n",
      "[1553 rows x 6 columns]\n",
      "\n",
      "Cantidad de filas después de la limpieza: 1553\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame original\n",
    "print(\"DataFrame Original:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Paso 1: Reemplazar cadenas vacías y None por NaN\n",
    "df_Modificar.replace(['', None], pd.NA, inplace=True)\n",
    "\n",
    "# Paso 2: Eliminar filas con cualquier valor NaN\n",
    "df_Modificar = df_Modificar.dropna()\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_used, index=False)\n",
    "\n",
    "# Mostrar el DataFrame después de eliminar las filas con NaN, '', o None\n",
    "print(\"\\nDataFrame después de eliminar filas con valores NaN, vacíos y None:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Verificar la cantidad de filas después de la limpieza\n",
    "print(f\"\\nCantidad de filas después de la limpieza: {df_Modificar.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal parece que este tampoco tiene valores nulos, lo cual es perfecto, asi no perdemos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna manufacturing_year es de tipo object y sus datos son de años, por lo que se debe convertir a entero. El problema es que hay algunos impostores de tipo string. Por lo que filtraremos esos casos y eliminaremos esas filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Filas del CSV antes de la limpieza de impostores:\n",
      "\n",
      "1553\n",
      "Cantidad de Filas del CSV despues de la limpieza de impostores:\n",
      "\n",
      "1503\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de Filas del CSV antes de la limpieza de impostores:\\n\")\n",
    "print(df_Modificar.shape[0])\n",
    "\n",
    "# Paso 1: Filtrar filas donde 'manufacturing_year' no empieza con un número\n",
    "df_Modificar = df_Modificar[df_Modificar['manufacturing_year'].str.match(r'^\\d')]\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_used, index=False)\n",
    "\n",
    "print(\"Cantidad de Filas del CSV despues de la limpieza de impostores:\\n\")\n",
    "print(df_Modificar.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convirtamos los tipos de datos del dataset para que sean adecuados para la fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de CSV antes de la conversion:\n",
      "\n",
      "car_name               object\n",
      "fuel_type              object\n",
      "kms_driven              int64\n",
      "transmission           object\n",
      "manufacturing_year     object\n",
      "price(in lakhs)       float64\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos del CSV despues de la conversion:\n",
      "\n",
      "car_name               object\n",
      "fuel_type              object\n",
      "kms_driven            float64\n",
      "transmission           object\n",
      "manufacturing_year      int64\n",
      "price(in lakhs)       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipos de datos de CSV antes de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Cambiar los tipos de datos de las columnas\n",
    "df_Modificar['manufacturing_year'] = df_Modificar['manufacturing_year'].astype(int)\n",
    "df_Modificar['kms_driven'] = df_Modificar['kms_driven'].astype(float)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_used, index=False)\n",
    "\n",
    "print(\"\\nTipos de datos del CSV despues de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora funcionaremos sus datos al dataset_fusionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de columnas del CSV antes de la Fusion: 23577\n",
      "Cantidad de filas del CSV después de la fusión: 25080\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de columnas del CSV antes de la Fusion: {df_fusion.shape[0]}\")\n",
    "\n",
    "# Seleccionar solo las columnas necesarias de df_Modificar\n",
    "df_Modificar_select = df_Modificar[['car_name', 'manufacturing_year', 'price(in lakhs)', 'kms_driven', 'fuel_type', 'transmission']]\n",
    "\n",
    "# Renombrar las columnas para que coincidan con las de df_fusion si es necesario\n",
    "df_Modificar_select.columns = ['Name', 'Year', 'Price', 'Mileage', 'Fuel', 'Transmission']\n",
    "\n",
    "# Concatenar df_Modificar_select a df_fusion\n",
    "df_fusion = pd.concat([df_fusion, df_Modificar_select], ignore_index=True)\n",
    "\n",
    "# Guardamos los cambios en el archivo CSV\n",
    "df_fusion.to_csv(ruta_fusion, index=False)\n",
    "\n",
    "# Verificar el resultado de la fusión\n",
    "print(f\"Cantidad de filas del CSV después de la fusión: {df_fusion.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuamos con df_dvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos un nuevo dataset para df_Modificar.\n",
    "df_Modificar = df_dvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora eliminaremos las columnas que no sean relevantes de df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CSV Data: \n",
      "\n",
      "Maker            object\n",
      "Genmodel         object\n",
      "Genmodel_ID      object\n",
      "Adv_ID           object\n",
      "Adv_year          int64\n",
      "Adv_month         int64\n",
      "Color            object\n",
      "Reg_year        float64\n",
      "Bodytype         object\n",
      "Runned_Miles     object\n",
      "Engin_size       object\n",
      "Gearbox          object\n",
      "Fuel_type        object\n",
      "Price            object\n",
      "Seat_num        float64\n",
      "Door_num        float64\n",
      "car_name         object\n",
      "dtype: object\n",
      "\n",
      "CSV Data after deleting the columns:\n",
      "\n",
      "Adv_year         int64\n",
      "Runned_Miles    object\n",
      "Gearbox         object\n",
      "Fuel_type       object\n",
      "Price           object\n",
      "car_name        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_Modificar['car_name'] = df_Modificar['Maker'] + ' ' + df_Modificar['Genmodel'] + ' ' + df_Modificar['Color']\n",
    "\n",
    "# display\n",
    "print(\"Original CSV Data: \\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Empezaremos a eliminar lo indeseado.\n",
    "columnasRelevantes = ['car_name', 'Adv_year', 'Price', 'Runned_Miles', 'Fuel_type', 'Gearbox']\n",
    "columnasParaEliminar = []\n",
    "\n",
    "# Identificamos y guardamos las columnas irrelevantes.\n",
    "for col in df_Modificar.columns:\n",
    "    if col not in columnasRelevantes:\n",
    "        columnasParaEliminar.append(col)\n",
    "\n",
    "# Eliminamos las columnas irrelevantes que fueron guardaas.\n",
    "df_Modificar = df_Modificar.drop(columnasParaEliminar, axis=1)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_dvm, index=False)\n",
    "\n",
    "# display\n",
    "print(\"\\nCSV Data after deleting the columns:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a eliminar cualquier valor nulo que tenga el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Original:\n",
      "        Adv_year Runned_Miles    Gearbox Fuel_type  Price  \\\n",
      "0           2018        60000  Automatic    Petrol  21500   \n",
      "1           2018        44000  Automatic    Petrol  28750   \n",
      "2           2017        55000  Automatic    Petrol  29999   \n",
      "3           2018        14000  Automatic    Petrol  34948   \n",
      "4           2017        61652  Automatic    Petrol  26555   \n",
      "...          ...          ...        ...       ...    ...   \n",
      "268250      2018         1800     Manual    Petrol   8750   \n",
      "268251      2018         2009     Manual       NaN   7995   \n",
      "268252      2018            6     Manual    Petrol  27950   \n",
      "268253      2018         1538     Manual    Petrol  34950   \n",
      "268254      2018          500     Manual    Petrol  29995   \n",
      "\n",
      "                      car_name  \n",
      "0        Bentley Arnage Silver  \n",
      "1          Bentley Arnage Grey  \n",
      "2          Bentley Arnage Blue  \n",
      "3         Bentley Arnage Green  \n",
      "4          Bentley Arnage Grey  \n",
      "...                        ...  \n",
      "268250  Westfield Sport Yellow  \n",
      "268251  Westfield Sport Yellow  \n",
      "268252           Zenos E10 Red  \n",
      "268253         Zenos E10 Green  \n",
      "268254          Zenos E10 Grey  \n",
      "\n",
      "[268255 rows x 6 columns]\n",
      "\n",
      "DataFrame después de eliminar filas con valores NaN, vacíos y None:\n",
      "        Adv_year Runned_Miles    Gearbox Fuel_type  Price  \\\n",
      "0           2018        60000  Automatic    Petrol  21500   \n",
      "1           2018        44000  Automatic    Petrol  28750   \n",
      "2           2017        55000  Automatic    Petrol  29999   \n",
      "3           2018        14000  Automatic    Petrol  34948   \n",
      "4           2017        61652  Automatic    Petrol  26555   \n",
      "...          ...          ...        ...       ...    ...   \n",
      "268249      2018       107000     Manual    Diesel   3684   \n",
      "268250      2018         1800     Manual    Petrol   8750   \n",
      "268252      2018            6     Manual    Petrol  27950   \n",
      "268253      2018         1538     Manual    Petrol  34950   \n",
      "268254      2018          500     Manual    Petrol  29995   \n",
      "\n",
      "                      car_name  \n",
      "0        Bentley Arnage Silver  \n",
      "1          Bentley Arnage Grey  \n",
      "2          Bentley Arnage Blue  \n",
      "3         Bentley Arnage Green  \n",
      "4          Bentley Arnage Grey  \n",
      "...                        ...  \n",
      "268249          Volvo V50 Blue  \n",
      "268250  Westfield Sport Yellow  \n",
      "268252           Zenos E10 Red  \n",
      "268253         Zenos E10 Green  \n",
      "268254          Zenos E10 Grey  \n",
      "\n",
      "[245042 rows x 6 columns]\n",
      "\n",
      "Cantidad de filas después de la limpieza: 245042\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame original\n",
    "print(\"DataFrame Original:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Paso 1: Reemplazar cadenas vacías y None por NaN\n",
    "df_Modificar.replace(['', None], pd.NA, inplace=True)\n",
    "\n",
    "# Paso 2: Eliminar filas con cualquier valor NaN\n",
    "df_Modificar = df_Modificar.dropna()\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_dvm, index=False)\n",
    "\n",
    "# Mostrar el DataFrame después de eliminar las filas con NaN, '', o None\n",
    "print(\"\\nDataFrame después de eliminar filas con valores NaN, vacíos y None:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Verificar la cantidad de filas después de la limpieza\n",
    "print(f\"\\nCantidad de filas después de la limpieza: {df_Modificar.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal parece que este tampoco tiene valores nulos, lo cual es perfecto, asi no perdemos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columna Runned_Miles y Price tienen el problema de que hay algunos impostores de tipo string entre ellas. Por lo que filtraremos esos casos y eliminaremos esas filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Filas del CSV antes de la limpieza de impostores:\n",
      "\n",
      "245042\n",
      "Cantidad de Filas del CSV despues de la limpieza de impostores:\n",
      "\n",
      "242361\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de Filas del CSV antes de la limpieza de impostores:\\n\")\n",
    "print(df_Modificar.shape[0])\n",
    "\n",
    "# Paso 1: Filtrar filas seleccionadas donde no empieza con un número\n",
    "df_Modificar = df_Modificar[df_Modificar['Price'].str.match(r'^\\d.*\\d$')]\n",
    "df_Modificar = df_Modificar[df_Modificar['Runned_Miles'].str.match(r'^\\d.*\\d$')]\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_dvm, index=False)\n",
    "\n",
    "print(\"Cantidad de Filas del CSV despues de la limpieza de impostores:\\n\")\n",
    "print(df_Modificar.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convirtamos los tipos de datos del dataset para que sean adecuados para la fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adv_year         int64\n",
      "Runned_Miles    object\n",
      "Gearbox         object\n",
      "Fuel_type       object\n",
      "Price           object\n",
      "car_name        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de CSV antes de la conversion:\n",
      "\n",
      "Adv_year         int64\n",
      "Runned_Miles    object\n",
      "Gearbox         object\n",
      "Fuel_type       object\n",
      "Price           object\n",
      "car_name        object\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos del CSV despues de la conversion:\n",
      "\n",
      "Adv_year          int64\n",
      "Runned_Miles    float64\n",
      "Gearbox          object\n",
      "Fuel_type        object\n",
      "Price           float64\n",
      "car_name         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipos de datos de CSV antes de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Cambiar los tipos de datos de las columnas\n",
    "df_Modificar['Price'] = df_Modificar['Price'].astype(float)\n",
    "df_Modificar['Runned_Miles'] = df_Modificar['Runned_Miles'].astype(float)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_dvm, index=False)\n",
    "\n",
    "print(\"\\nTipos de datos del CSV despues de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora funcionaremos sus datos al dataset_fusionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de columnas del CSV antes de la Fusion: 25080\n",
      "Cantidad de filas del CSV después de la fusión: 267441\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de columnas del CSV antes de la Fusion: {df_fusion.shape[0]}\")\n",
    "\n",
    "# Seleccionar solo las columnas necesarias de df_Modificar\n",
    "df_Modificar_select = df_Modificar[['car_name', 'Adv_year', 'Price', 'Runned_Miles', 'Fuel_type', 'Gearbox']]\n",
    "\n",
    "# Renombrar las columnas para que coincidan con las de df_fusion si es necesario\n",
    "df_Modificar_select.columns = ['Name', 'Year', 'Price', 'Mileage', 'Fuel', 'Transmission']\n",
    "\n",
    "# Concatenar df_Modificar_select a df_fusion\n",
    "df_fusion = pd.concat([df_fusion, df_Modificar_select], ignore_index=True)\n",
    "\n",
    "# Guardamos los cambios en el archivo CSV\n",
    "df_fusion.to_csv(ruta_fusion, index=False)\n",
    "\n",
    "# Verificar el resultado de la fusión\n",
    "print(f\"Cantidad de filas del CSV después de la fusión: {df_fusion.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuamos con df_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos un nuevo dataset para df_Modificar.\n",
    "df_Modificar = df_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model  year  price transmission  mileage fuelType  tax   mpg  \\\n",
      "0                I10  2017   7495       Manual    11630   Petrol  145  60.1   \n",
      "1               Polo  2017  10989       Manual     9200   Petrol  145  58.9   \n",
      "2           2 Series  2019  27990    Semi-Auto     1614   Diesel  145  49.6   \n",
      "3       Yeti Outdoor  2017  12495       Manual    30960   Diesel  150  62.8   \n",
      "4             Fiesta  2017   7999       Manual    19353   Petrol  125  54.3   \n",
      "...              ...   ...    ...          ...      ...      ...  ...   ...   \n",
      "97707         Fiesta  2017  10447    Automatic     8337   Petrol  145  54.3   \n",
      "97708       3 Series  2014  14995       Manual    25372   Diesel   30  61.4   \n",
      "97709         Fiesta  2017   8950       Manual    19910   Petrol  125  54.3   \n",
      "97710          Astra  2017  10700    Automatic    24468   Petrol  125  50.4   \n",
      "97711    Grandland X  2019  15798       Manual    10586   Diesel  150  48.7   \n",
      "\n",
      "       engineSize Manufacturer  \n",
      "0             1.0       hyundi  \n",
      "1             1.0   volkswagen  \n",
      "2             2.0          BMW  \n",
      "3             2.0        skoda  \n",
      "4             1.2         ford  \n",
      "...           ...          ...  \n",
      "97707         1.0         ford  \n",
      "97708         2.0          BMW  \n",
      "97709         1.2         ford  \n",
      "97710         1.4     vauxhall  \n",
      "97711         1.5     vauxhall  \n",
      "\n",
      "[97712 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora eliminaremos las columnas que no sean relevantes de df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CSV Data: \n",
      "\n",
      "model            object\n",
      "year              int64\n",
      "price             int64\n",
      "transmission     object\n",
      "mileage           int64\n",
      "fuelType         object\n",
      "tax               int64\n",
      "mpg             float64\n",
      "engineSize      float64\n",
      "Manufacturer     object\n",
      "car_name         object\n",
      "dtype: object\n",
      "\n",
      "CSV Data after deleting the columns:\n",
      "\n",
      "year             int64\n",
      "price            int64\n",
      "transmission    object\n",
      "mileage          int64\n",
      "fuelType        object\n",
      "car_name        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_Modificar['car_name'] = df_Modificar['Manufacturer'] + ' ' + df_Modificar['model']\n",
    "\n",
    "# display\n",
    "print(\"Original CSV Data: \\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Empezaremos a eliminar lo indeseado.\n",
    "columnasRelevantes = ['car_name', 'year', 'price', 'mileage', 'fuelType', 'transmission']\n",
    "columnasParaEliminar = []\n",
    "\n",
    "# Identificamos y guardamos las columnas irrelevantes.\n",
    "for col in df_Modificar.columns:\n",
    "    if col not in columnasRelevantes:\n",
    "        columnasParaEliminar.append(col)\n",
    "\n",
    "# Eliminamos las columnas irrelevantes que fueron guardaas.\n",
    "df_Modificar = df_Modificar.drop(columnasParaEliminar, axis=1)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_world, index=False)\n",
    "\n",
    "# display\n",
    "print(\"\\nCSV Data after deleting the columns:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a eliminar cualquier valor nulo que tenga el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Original:\n",
      "       year  price transmission  mileage fuelType               car_name\n",
      "0      2017   7495       Manual    11630   Petrol            hyundi  I10\n",
      "1      2017  10989       Manual     9200   Petrol       volkswagen  Polo\n",
      "2      2019  27990    Semi-Auto     1614   Diesel          BMW  2 Series\n",
      "3      2017  12495       Manual    30960   Diesel    skoda  Yeti Outdoor\n",
      "4      2017   7999       Manual    19353   Petrol           ford  Fiesta\n",
      "...     ...    ...          ...      ...      ...                    ...\n",
      "97707  2017  10447    Automatic     8337   Petrol           ford  Fiesta\n",
      "97708  2014  14995       Manual    25372   Diesel          BMW  3 Series\n",
      "97709  2017   8950       Manual    19910   Petrol           ford  Fiesta\n",
      "97710  2017  10700    Automatic    24468   Petrol        vauxhall  Astra\n",
      "97711  2019  15798       Manual    10586   Diesel  vauxhall  Grandland X\n",
      "\n",
      "[97712 rows x 6 columns]\n",
      "\n",
      "DataFrame después de eliminar filas con valores NaN, vacíos y None:\n",
      "       year  price transmission  mileage fuelType               car_name\n",
      "0      2017   7495       Manual    11630   Petrol            hyundi  I10\n",
      "1      2017  10989       Manual     9200   Petrol       volkswagen  Polo\n",
      "2      2019  27990    Semi-Auto     1614   Diesel          BMW  2 Series\n",
      "3      2017  12495       Manual    30960   Diesel    skoda  Yeti Outdoor\n",
      "4      2017   7999       Manual    19353   Petrol           ford  Fiesta\n",
      "...     ...    ...          ...      ...      ...                    ...\n",
      "97707  2017  10447    Automatic     8337   Petrol           ford  Fiesta\n",
      "97708  2014  14995       Manual    25372   Diesel          BMW  3 Series\n",
      "97709  2017   8950       Manual    19910   Petrol           ford  Fiesta\n",
      "97710  2017  10700    Automatic    24468   Petrol        vauxhall  Astra\n",
      "97711  2019  15798       Manual    10586   Diesel  vauxhall  Grandland X\n",
      "\n",
      "[97712 rows x 6 columns]\n",
      "\n",
      "Cantidad de filas después de la limpieza: 97712\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame original\n",
    "print(\"DataFrame Original:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Paso 1: Reemplazar cadenas vacías y None por NaN\n",
    "df_Modificar.replace(['', None], pd.NA, inplace=True)\n",
    "\n",
    "# Paso 2: Eliminar filas con cualquier valor NaN\n",
    "df_Modificar = df_Modificar.dropna()\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_world, index=False)\n",
    "\n",
    "# Mostrar el DataFrame después de eliminar las filas con NaN, '', o None\n",
    "print(\"\\nDataFrame después de eliminar filas con valores NaN, vacíos y None:\")\n",
    "print(df_Modificar)\n",
    "\n",
    "# Verificar la cantidad de filas después de la limpieza\n",
    "print(f\"\\nCantidad de filas después de la limpieza: {df_Modificar.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal parece que este tampoco tiene valores nulos, lo cual es perfecto, asi no perdemos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convirtamos los tipos de datos del dataset para que sean adecuados para la fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year             int64\n",
      "price            int64\n",
      "transmission    object\n",
      "mileage          int64\n",
      "fuelType        object\n",
      "car_name        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de CSV antes de la conversion:\n",
      "\n",
      "year             int64\n",
      "price            int64\n",
      "transmission    object\n",
      "mileage          int64\n",
      "fuelType        object\n",
      "car_name        object\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos del CSV despues de la conversion:\n",
      "\n",
      "year              int64\n",
      "price           float64\n",
      "transmission     object\n",
      "mileage         float64\n",
      "fuelType         object\n",
      "car_name         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipos de datos de CSV antes de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)\n",
    "\n",
    "# Cambiar los tipos de datos de las columnas\n",
    "df_Modificar['price'] = df_Modificar['price'].astype(float)\n",
    "df_Modificar['mileage'] = df_Modificar['mileage'].astype(float)\n",
    "\n",
    "# Guardamos los cambios del CSV en el mismo archivo CSV.\n",
    "df_Modificar.to_csv(ruta_world, index=False)\n",
    "\n",
    "print(\"\\nTipos de datos del CSV despues de la conversion:\\n\")\n",
    "print(df_Modificar.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora funcionaremos sus datos al dataset_fusionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de columnas del CSV antes de la Fusion: 267441\n",
      "Cantidad de filas del CSV después de la fusión: 365153\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de columnas del CSV antes de la Fusion: {df_fusion.shape[0]}\")\n",
    "\n",
    "# Seleccionar solo las columnas necesarias de df_Modificar\n",
    "df_Modificar_select = df_Modificar[['car_name', 'year', 'price', 'mileage', 'fuelType', 'transmission']]\n",
    "\n",
    "# Renombrar las columnas para que coincidan con las de df_fusion si es necesario\n",
    "df_Modificar_select.columns = ['Name', 'Year', 'Price', 'Mileage', 'Fuel', 'Transmission']\n",
    "\n",
    "# Concatenar df_Modificar_select a df_fusion\n",
    "df_fusion = pd.concat([df_fusion, df_Modificar_select], ignore_index=True)\n",
    "\n",
    "# Guardamos los cambios en el archivo CSV\n",
    "df_fusion.to_csv(ruta_fusion, index=False)\n",
    "\n",
    "# Verificar el resultado de la fusión\n",
    "print(f\"Cantidad de filas del CSV después de la fusión: {df_fusion.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Al final el archivo fusionado nos quedo con 365,153 filas y 6 columnas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
